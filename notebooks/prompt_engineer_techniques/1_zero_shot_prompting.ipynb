{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c4d3e7f",
   "metadata": {},
   "source": [
    "# Zero-shot Prompting com Modelos de Linguagem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fb2bd5",
   "metadata": {},
   "source": [
    "## Introdução aos Modelos de Linguagem de Grande Escala (LLMs)\n",
    "\n",
    "Os modelos de linguagem de grande escala (LLMs), como o GPT-3.5 Turbo, GPT-4 e Claude 3, foram treinados em grandes volumes de dados e ajustados para seguir instruções. Essa capacidade de processamento em larga escala permite que esses modelos realizem algumas tarefas sem a necessidade de exemplos, uma habilidade conhecida como **zero-shot prompting**.\n",
    "\n",
    "No **zero-shot prompting**, fornecemos ao modelo apenas uma instrução, sem exemplos adicionais. A ideia é que, devido ao seu treinamento prévio, o modelo compreenda a tarefa diretamente a partir da instrução e responda corretamente. Esse método é útil para tarefas simples e diretas, mas pode falhar em tarefas que exigem raciocínio complexo ou conhecimentos específicos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36646ca",
   "metadata": {},
   "source": [
    "## Conceito de Zero-shot Prompting\n",
    "\n",
    "Zero-shot prompting refere-se ao uso de um modelo de linguagem para realizar uma tarefa sem fornecer exemplos no prompt. Isso é possível porque os LLMs foram expostos a uma ampla gama de dados durante o treinamento e conseguem deduzir padrões e significados de palavras e frases.\n",
    "\n",
    "Um exemplo típico de zero-shot é a **classificação de sentimento**. No exemplo a seguir, o modelo precisa identificar o tom de uma frase e classificá-la como 'positiva', 'negativa' ou 'neutra', sem que exemplos específicos de sentimento sejam apresentados no prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c2d67b",
   "metadata": {},
   "source": [
    "### Exemplo de Zero-shot Prompting: Classificação de Sentimento\n",
    "\n",
    "No exemplo abaixo, pedimos ao modelo para classificar o sentimento de uma frase. Note que não fornecemos exemplos anteriores para guiar o modelo, apenas uma instrução direta.\n",
    "\n",
    "- **Prompt**: Classifique o texto como 'neutro', 'negativo' ou 'positivo'.\n",
    "- **Texto**: 'Acho que as férias foram boas.'\n",
    "\n",
    "O modelo deve entender o termo 'sentimento' e responder com a classificação correta, mostrando a capacidade de zero-shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f5a6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae0f061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração do modelo\n",
    "chat = ChatOllama(model=\"llama3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e52457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'Você é um assistente especializado em análise de sentimentos.'),\n",
    "    ('human', 'Classifique o texto como \"neutro\", \"negativo\" ou \"positivo\".\\nTexto: {texto}\\nSentimento:')\n",
    "])\n",
    "\n",
    "def classificar_sentimento_zero_shot(texto):\n",
    "    # Invoca o modelo com a frase fornecida\n",
    "    resposta = template | chat\n",
    "    output = resposta.invoke({\"texto\": texto})\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eb8fd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar a função de classificação em zero-shot\n",
    "texto_para_classificar = \"Acho que as férias foram boas.\"\n",
    "resultado_classificar_sentimento_zero_shot = classificar_sentimento_zero_shot(texto_para_classificar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5855c6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificação (Zero-shot): Positivo!\n"
     ]
    }
   ],
   "source": [
    "print(f\"Classificação (Zero-shot): {resultado_classificar_sentimento_zero_shot.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85985866",
   "metadata": {},
   "source": [
    "## Ajuste de Instruções (Instruction Tuning) e RLHF\n",
    "\n",
    "O ajuste de instruções, ou **instruction tuning**, aprimora a capacidade dos modelos em realizar tarefas zero-shot ao treiná-los com datasets descritos via instruções (Wei et al., 2022). Isso torna os modelos mais eficientes em entender e seguir comandos diretos, como o pedido para classificar um sentimento.\n",
    "\n",
    "Além disso, o **Reinforcement Learning from Human Feedback** (RLHF) é uma técnica que alinha o modelo para se ajustar melhor às preferências humanas [RLHF (arxiv:1706.03741)](https://arxiv.org/abs/1706.03741). Esse método, utilizado em modelos como o ChatGPT, melhora a resposta a tarefas zero-shot, tornando o modelo mais sensível a nuances de linguagem e preferências do usuário."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcf292d",
   "metadata": {},
   "source": [
    "### Exemplo de Zero-shot com Classificação de Sentimento e Explicação\n",
    "\n",
    "No próximo exemplo, pedimos ao modelo não apenas para classificar o sentimento de uma frase, mas também para explicar o motivo da classificação.\n",
    "\n",
    "- **Prompt**: Classifique o texto e explique a razão.\n",
    "- **Texto**: 'O serviço foi péssimo.'\n",
    "\n",
    "Este tipo de prompt incentiva o modelo a fornecer um raciocínio, ainda que seja um zero-shot, aproveitando o ajuste de instruções e o RLHF para aumentar a precisão da resposta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "becfdc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Novo template para classificação com explicação\n",
    "template_explicacao = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'Você é um assistente que classifica o sentimento e explica a razão da classificação.'),\n",
    "    ('human', 'Classifique o texto como \"neutro\", \"negativo\" ou \"positivo\" e explique o motivo.\\nTexto: {texto}\\nSentimento e Explicação:')\n",
    "])\n",
    "\n",
    "def classificar_sentimento_com_explicacao_zero_shot(texto):\n",
    "    # Invoca o modelo com a frase fornecida\n",
    "    resposta = template_explicacao | chat\n",
    "    output = resposta.invoke({\"texto\": texto})\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03cb3e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar a função de classificação com explicação\n",
    "texto_para_classificar_explicacao = \"O serviço foi péssimo.\"\n",
    "resultado_classificar_sentimento_com_explicacao = classificar_sentimento_com_explicacao_zero_shot(texto_para_classificar_explicacao)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25818a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificação com Explicação (Zero-shot): Classificação: Negativa\n",
      "\n",
      "Motivo: A palavra-chave do texto é \"péssimo\", que é um termo fortemente negativo, expressando uma forte desaprovação ou descontentamento com o serviço. Além disso, a falta de palavras positivas e a ausência de justificativas para o serviço ser ruim também contribuem para essa classificação.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Classificação com Explicação (Zero-shot): {resultado_classificar_sentimento_com_explicacao.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90f51c4",
   "metadata": {},
   "source": [
    "## Conclusão sobre Zero-shot Prompting e Limitações\n",
    "\n",
    "O zero-shot prompting é uma ferramenta poderosa para tarefas onde o modelo consegue identificar padrões com base apenas em instruções diretas. No entanto, ele tem limitações, especialmente em tarefas que requerem raciocínio mais complexo ou conhecimento de contexto específico.\n",
    "\n",
    "Quando o zero-shot não é suficiente, é recomendável considerar o uso de **few-shot prompting**, onde exemplos adicionais são fornecidos ao modelo, ou até técnicas mais avançadas, como o **Chain-of-Thought Prompting** para problemas que exigem múltiplas etapas de raciocínio.\n",
    "\n",
    "Aprendemos que o ajuste de instruções, como descrito em [Wei et al., 2022](https://arxiv.org/pdf/2109.01652), e o RLHF [RLHF (arxiv:1706.03741)](https://arxiv.org/abs/1706.03741), são métodos cruciais para melhorar a eficiência dos modelos em tarefas zero-shot."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
